{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Vocabulary for Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "script_dir = os.path.dirname(os.path.abspath('vocab.ipynb'))\n",
    "parent_directory = os.path.dirname(script_dir)\n",
    "module_directory = os.path.join(parent_directory, 'module') \n",
    "utils_directory = os.path.join(parent_directory, 'utils') \n",
    "\n",
    "if (parent_directory not in sys.path):\n",
    "    sys.path.append(parent_directory)\n",
    "    \n",
    "if (module_directory not in sys.path):\n",
    "    sys.path.append(module_directory)\n",
    "    \n",
    "if (utils_directory not in sys.path):\n",
    "    sys.path.append(utils_directory)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.preprocess.bpe import BpeArgs, Encoder\n",
    "from module.preprocess.load_and_batch import BatchMeta\n",
    "from module.preprocess.load_and_batch import TableInfoManagers\n",
    "from tqdm import tqdm\n",
    "from utils import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------> Size of train dataset: (1526659, 224) <------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 224)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>actualdpdtolerance_344P</th><th>amtinstpaidbefduel24m_4187115A</th><th>annuity_780A</th><th>annuitynextmonth_57A</th><th>applicationcnt_361L</th><th>applications30d_658L</th><th>applicationscnt_1086L</th><th>applicationscnt_464L</th><th>applicationscnt_629L</th><th>applicationscnt_867L</th><th>avgdbddpdlast24m_3658932P</th><th>avgdbddpdlast3m_4187120P</th><th>avgdbdtollast24m_4525197P</th><th>avgdpdtolclosure24_3658938P</th><th>avginstallast24m_3658937A</th><th>avglnamtstart24m_4525187A</th><th>avgmaxdpdlast9m_3716943P</th><th>avgoutstandbalancel6m_4187114A</th><th>avgpmtlast12m_4525200A</th><th>bankacctype_710L</th><th>cardtype_51L</th><th>clientscnt12m_3712952L</th><th>clientscnt3m_3712950L</th><th>clientscnt6m_3712949L</th><th>clientscnt_100L</th><th>clientscnt_1022L</th><th>clientscnt_1071L</th><th>clientscnt_1130L</th><th>clientscnt_136L</th><th>clientscnt_157L</th><th>clientscnt_257L</th><th>clientscnt_304L</th><th>clientscnt_360L</th><th>clientscnt_493L</th><th>clientscnt_533L</th><th>clientscnt_887L</th><th>&hellip;</th><th>formonth_118L</th><th>formonth_206L</th><th>formonth_535L</th><th>forquarter_1017L</th><th>forquarter_462L</th><th>forquarter_634L</th><th>fortoday_1092L</th><th>forweek_1077L</th><th>forweek_528L</th><th>forweek_601L</th><th>foryear_618L</th><th>foryear_818L</th><th>foryear_850L</th><th>fourthquarter_440L</th><th>maritalst_385M</th><th>maritalst_893M</th><th>numberofqueries_373L</th><th>pmtaverage_3A</th><th>pmtaverage_4527227A</th><th>pmtaverage_4955615A</th><th>pmtcount_4527229L</th><th>pmtcount_4955617L</th><th>pmtcount_693L</th><th>pmtscount_423L</th><th>pmtssum_45A</th><th>requesttype_4525192L</th><th>responsedate_1012D</th><th>responsedate_4527233D</th><th>responsedate_4917613D</th><th>riskassesment_302T</th><th>riskassesment_940T</th><th>secondquarter_766L</th><th>thirdquarter_1082L</th><th>date_decision</th><th>MONTH</th><th>WEEK_NUM</th><th>target</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>date</td><td>date</td><td>date</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>date</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>null</td><td>null</td><td>1917.6</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019-01-03</td><td>201901</td><td>0</td><td>0</td></tr><tr><td>1</td><td>null</td><td>null</td><td>3134.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;0.0&quot;</td><td>3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019-01-03</td><td>201901</td><td>0</td><td>0</td></tr><tr><td>2</td><td>null</td><td>null</td><td>4937.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019-01-04</td><td>201901</td><td>0</td><td>0</td></tr><tr><td>3</td><td>null</td><td>null</td><td>4643.6</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019-01-03</td><td>201901</td><td>0</td><td>0</td></tr><tr><td>4</td><td>null</td><td>null</td><td>3390.2</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019-01-04</td><td>201901</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 224)\n",
       "┌─────────┬─────────────┬─────────────┬─────────────┬───┬─────────────┬────────┬──────────┬────────┐\n",
       "│ case_id ┆ actualdpdto ┆ amtinstpaid ┆ annuity_780 ┆ … ┆ date_decisi ┆ MONTH  ┆ WEEK_NUM ┆ target │\n",
       "│ ---     ┆ lerance_344 ┆ befduel24m_ ┆ A           ┆   ┆ on          ┆ ---    ┆ ---      ┆ ---    │\n",
       "│ i64     ┆ P           ┆ 4187115A    ┆ ---         ┆   ┆ ---         ┆ i64    ┆ i64      ┆ i64    │\n",
       "│         ┆ ---         ┆ ---         ┆ f64         ┆   ┆ date        ┆        ┆          ┆        │\n",
       "│         ┆ f64         ┆ f64         ┆             ┆   ┆             ┆        ┆          ┆        │\n",
       "╞═════════╪═════════════╪═════════════╪═════════════╪═══╪═════════════╪════════╪══════════╪════════╡\n",
       "│ 0       ┆ null        ┆ null        ┆ 1917.6      ┆ … ┆ 2019-01-03  ┆ 201901 ┆ 0        ┆ 0      │\n",
       "│ 1       ┆ null        ┆ null        ┆ 3134.0      ┆ … ┆ 2019-01-03  ┆ 201901 ┆ 0        ┆ 0      │\n",
       "│ 2       ┆ null        ┆ null        ┆ 4937.0      ┆ … ┆ 2019-01-04  ┆ 201901 ┆ 0        ┆ 0      │\n",
       "│ 3       ┆ null        ┆ null        ┆ 4643.6      ┆ … ┆ 2019-01-03  ┆ 201901 ┆ 0        ┆ 0      │\n",
       "│ 4       ┆ null        ┆ null        ┆ 3390.2      ┆ … ┆ 2019-01-04  ┆ 201901 ┆ 0        ┆ 1      │\n",
       "└─────────┴─────────────┴─────────────┴─────────────┴───┴─────────────┴────────┴──────────┴────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TableInfoManagers.load_data_downloaded(config.DATA_LOCATION, cat= \"train\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Vocabulary\n",
    "\n",
    "## Overview\n",
    "To construct the vocabulary, a rule-based approach is employed to segment the text into tokens. Different categories of words are processed according to their characteristics.\n",
    "\n",
    "## Categories\n",
    "- **Common Words**: Utilizing the NLTK library, common words are identified and stored in a `common` vocabulary.\n",
    "- **Special Words**: This category includes identifiers such as `<tags>` for numeric types and column headers, which are crucial for semantic processing.\n",
    "- **Base Words**: Includes all tokens that can be encoded using ASCII characters, forming the foundation of the vocabulary.\n",
    "- **Paired Words**: Refers to combinations of words merged during the Byte Pair Encoding (BPE) process, crucial for efficient encoding of common word pairings.\n",
    "\n",
    "# Training Process\n",
    "\n",
    "## Methodology\n",
    "The training employs a combination of Byte Pair Encoding (BPE) for subwords and common words. Special words or tags are exempt from pairing during BPE to preserve their uniqueness and facilitate easy identification.\n",
    "- **Unique Handling of Special Words**: During the BPE algorithm, special words are not merged into pairs, ensuring that these elements remain distinct for subsequent embedding analysis.\n",
    "- **Use of IQR**: An Interquartile Range (IQR) method is used to determine which pairs to merge. Only pairs that are clear outliers in the text snippet are merged, based on the premise that merging less frequent, outlier pairs prevents the loss of important information.\n",
    "- **Threshold Adjustment**: The current IQR threshold is set at 1.5, but this parameter is adjustable in future experiments to optimize the \n",
    "\n",
    "## Code Snippet\n",
    "\n",
    "```python\n",
    "from module.preprocess.load_and_batch import TableHandler\n",
    "\n",
    "# Function for building\n",
    "def build(enc :Encoder, verbose=False, batch_size:int = 128):\n",
    "    col_types = data.dtypes\n",
    "    col_names = data.columns\n",
    "    ignore_list = [\"case_id\", 'target']\n",
    "    agg_info = BatchMeta()\n",
    "    \n",
    "    with tqdm(total=data.height, desc=\"Processing batch\") as pbar:\n",
    "        for i in range(0, data.height, batch_size):\n",
    "            batch = data.slice(i, min(batch_size, data.height - i))  \n",
    "            \n",
    "            for row in batch.rows():\n",
    "                TableHandler.row_to_text(row, agg_info, col_types, col_names, ignore_list, output=[])\n",
    "                enc.process(agg_info.texts[-1])\n",
    "                if verbose:\n",
    "                    print(agg_info.texts[-1])\n",
    "                pbar.update(1)\n",
    "                \n",
    "            # Process the batch here if needed\n",
    "            agg_info = BatchMeta()  # Reset for the next batch\n",
    "            \n",
    "        pbar.close()\n",
    "\n",
    "# Running: create BPE, Encode \n",
    "bpe_args = BpeArgs(\n",
    "    target_context = 256,\n",
    "    max_vocab_size = 10000, # controls the total vocab size\n",
    "    store_loc = config.BASE_LOCATION, # Where to store or load information post\n",
    "    adhoc_tokens = ['CLS', 'PAD'], # List of special tokens to be included\n",
    "    adhoc_words = data.columns # Special words that aren't key tags but should be included\n",
    ")\n",
    "\n",
    "text_encoder = Encoder(bpe_args)\n",
    "build(text_encoder, verbose=False)  \n",
    "text_encoder.save_state(config.BASE_LOCATION)\n",
    "```merging strategy.idation are needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "- The use of IQR in BPE training is a novel approach that adds an analytical dimension to the merging process, potentially enhancing the model's ability to recognize and utilize important lexical features from the text. This strategy is postulated to identify the most performant features from all columns after training, although further experimentation and validation are needed.\n",
    "- The Total vocabulary length is **861** tokens and it averages a **60%** compression rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Encoded Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty instantiation. Ensure to load from pickle file location\n",
      "+-----------------------------------------------+\n",
      "|               Analysis Results                |\n",
      "+-----------------------------------------------+\n",
      "| Length of original list              :   1992 |\n",
      "| Number of unique tokens in original  :    262 |\n",
      "| Length of compressed list            :    717 |\n",
      "| Number of unique tokens in compressed:    254 |\n",
      "| Final compression ratio              : 0.640  |\n",
      "| Length of vocabulary                 :    861 |\n",
      "+-----------------------------------------------+\n",
      "+-----------------------------------------------+\n",
      "|               Analysis Results                |\n",
      "+-----------------------------------------------+\n",
      "| Length of original list              :   1953 |\n",
      "| Number of unique tokens in original  :    261 |\n",
      "| Length of compressed list            :    712 |\n",
      "| Number of unique tokens in compressed:    254 |\n",
      "| Final compression ratio              : 0.635  |\n",
      "| Length of vocabulary                 :    861 |\n",
      "+-----------------------------------------------+\n",
      "+-----------------------------------------------+\n",
      "|               Analysis Results                |\n",
      "+-----------------------------------------------+\n",
      "| Length of original list              :   1793 |\n",
      "| Number of unique tokens in original  :    264 |\n",
      "| Length of compressed list            :    745 |\n",
      "| Number of unique tokens in compressed:    276 |\n",
      "| Final compression ratio              : 0.584  |\n",
      "| Length of vocabulary                 :    861 |\n",
      "+-----------------------------------------------+\n",
      "+-----------------------------------------------+\n",
      "|               Analysis Results                |\n",
      "+-----------------------------------------------+\n",
      "| Length of original list              :   2002 |\n",
      "| Number of unique tokens in original  :    258 |\n",
      "| Length of compressed list            :    699 |\n",
      "| Number of unique tokens in compressed:    250 |\n",
      "| Final compression ratio              : 0.651  |\n",
      "| Length of vocabulary                 :    861 |\n",
      "+-----------------------------------------------+\n",
      "+-----------------------------------------------+\n",
      "|               Analysis Results                |\n",
      "+-----------------------------------------------+\n",
      "| Length of original list              :   1812 |\n",
      "| Number of unique tokens in original  :    262 |\n",
      "| Length of compressed list            :    732 |\n",
      "| Number of unique tokens in compressed:    264 |\n",
      "| Final compression ratio              : 0.596  |\n",
      "| Length of vocabulary                 :    861 |\n",
      "+-----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from module.preprocess.load_and_batch import TableHandler\n",
    "# load from validation set\n",
    "import random\n",
    "random_index = random.randint(1, data.height - 1)\n",
    "trial = data.slice(random_index, 5)\n",
    "col_types = data.dtypes\n",
    "col_names = data.columns\n",
    "ignore_list = [\"case_id\", 'target', 'WEEK_NUM']\n",
    "agg_info = BatchMeta()\n",
    "\n",
    "encoder = Encoder(None)\n",
    "encoder.load_state(config.BASE_LOCATION)\n",
    "\n",
    "for row in trial.rows():\n",
    "    TableHandler.row_to_text(row, agg_info, col_types, col_names, ignore_list, output=[])\n",
    "    encoder.encode_text(agg_info.texts[-1], verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "As can be seen the compressed length tends to be between **700 - 800** range. To accomodate the chances of new tokens that haven't been encountered we set the context length for the algorithm to 1024 which will be used during the training process. This allows for flexibility at runtime for longer text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
